{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# from src.encoder import encode, decode\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,f1_score,precision_score, recall_score,classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "from src.ANN import *\n",
    "from src.dump import *\n",
    "from sklearn.model_selection import KFold\n",
    "from src.metrics import confusion_matrix_local,print_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Iris.csv')\n",
    "df = df.drop(['Id'],axis=1)\n",
    "\n",
    "x_train = df[['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm']]\n",
    "y_train = df['Species'].map({\n",
    "    \"Iris-setosa\": 0,\n",
    "    \"Iris-versicolor\": 1,\n",
    "    \"Iris-virginica\": 2\n",
    "}).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelled_y = []\n",
    "for i in y_train:\n",
    "    a = [0,0,0]\n",
    "    a[i] = 1\n",
    "    labelled_y.append(a)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(x_train)\n",
    "Y = np.array(labelled_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, test_x, train_y, test_y = train_test_split(X, Y, test_size=0.20, random_state=420)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential(random_state=42069)\n",
    "model.add(Dense(units=16, input_dim=4, activation_function=\"linear\"))\n",
    "model.add(Dense(units=8, activation_function=\"relu\"))\n",
    "model.add(Dense(units=4, activation_function=\"linear\"))\n",
    "model.add(Dense(units=3, activation_function=\"relu\"))\n",
    "model.add(Dense(units=3, activation_function=\"sigmoid\"))\n",
    "model.compile(\"sum_squared_error\", 0.0001, 0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(X, Y, batch_size=1, epoch=50)\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pembelajaran train-test 90-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_x, train_y, batch_size=1, epoch=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "decode_test_y = []\n",
    "for i in test_y:\n",
    "  decode_test_y.append(np.argmax(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "decode_pred_y = []\n",
    "for i in y_pred:\n",
    "  decode_pred_y.append(np.argmax(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0, 1: 1, 2: 2}\n",
      "confusion matrix:\n",
      "[[13  0  0]\n",
      " [ 0  9  0]\n",
      " [ 0  2  6]]\n",
      "Performance Metrics:\n",
      "attribute:  0\n",
      "accuracy: 1.0\n",
      "precision: 1.0\n",
      "recall: 1.0\n",
      "f1: 1.0\n",
      "\n",
      "attribute:  1\n",
      "accuracy: 0.9333333333333333\n",
      "precision: 0.8181818181818182\n",
      "recall: 1.0\n",
      "f1: 0.9\n",
      "\n",
      "attribute:  2\n",
      "accuracy: 0.9333333333333333\n",
      "precision: 1.0\n",
      "recall: 0.75\n",
      "f1: 0.8571428571428571\n",
      "\n",
      "\n",
      "\n",
      "confusion matrix from sklearn:\n",
      "[[13  0  0]\n",
      " [ 0  9  2]\n",
      " [ 0  0  6]]\n",
      "Performance Metrics from sklearn:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     1.000     1.000        13\n",
      "           1      1.000     0.818     0.900        11\n",
      "           2      0.750     1.000     0.857         6\n",
      "\n",
      "    accuracy                          0.933        30\n",
      "   macro avg      0.917     0.939     0.919        30\n",
      "weighted avg      0.950     0.933     0.935        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print(\"predicted label:\")\n",
    "# print(decode_pred_y)\n",
    "# print(\"true label:\")\n",
    "# print(decode_test_y)\n",
    "conf_mat = confusion_matrix_local(decode_pred_y, decode_test_y)\n",
    "print(\"confusion matrix:\")\n",
    "print(conf_mat)\n",
    "print(\"Performance Metrics:\")\n",
    "print_scores(conf_mat,[0,1,2])\n",
    "print(\"\\n\")\n",
    "print(\"confusion matrix from sklearn:\")\n",
    "print(confusion_matrix(y_pred=decode_pred_y, y_true=decode_test_y))\n",
    "print(\"Performance Metrics from sklearn:\")\n",
    "print(classification_report(y_pred=decode_pred_y, y_true=decode_test_y, digits=3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pembelajaran cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "{0: 0}\n",
      "Performance Metrics:\n",
      "[0]\n",
      "attribute:  0\n",
      "accuracy: 1.0\n",
      "precision: 1.0\n",
      "recall: 1.0\n",
      "f1: 1.0\n",
      "\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "{0: 0}\n",
      "Performance Metrics:\n",
      "[0]\n",
      "attribute:  0\n",
      "accuracy: 1.0\n",
      "precision: 1.0\n",
      "recall: 1.0\n",
      "f1: 1.0\n",
      "\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "{0: 0}\n",
      "Performance Metrics:\n",
      "[0]\n",
      "attribute:  0\n",
      "accuracy: 1.0\n",
      "precision: 1.0\n",
      "recall: 1.0\n",
      "f1: 1.0\n",
      "\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "{0: 0, 1: 1}\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_25124/432648493.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     46\u001b[0m   \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdecode_pred_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m   \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdecode_test_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m   \u001b[0mconf_mat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfusion_matrix_local\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdecode_pred_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecode_test_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m   \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Performance Metrics:\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m   \u001b[0mtemp_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdecode_pred_y\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdecode_test_y\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\git\\ArtificialNeuralNetwork\\src\\metrics.py\u001b[0m in \u001b[0;36mconfusion_matrix_local\u001b[1;34m(pred_y, validation_y)\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;31m# fill in the confusion matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m         \u001b[0mconf_matrix\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mval_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpred_y\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mval_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvalidation_y\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;31m#     print(conf_matrix)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 2"
     ]
    }
   ],
   "source": [
    "accurations = []\n",
    "num_data = len(X)\n",
    "k_fold = 10\n",
    "# kf = KFold(n_splits=k_fold)\n",
    "# for train, test in kf.split(X):\n",
    "#   train_x, test_x = X[train], X[test]\n",
    "#   train_y, test_y = Y[train], Y[test]\n",
    "#   print(train_x.shape)\n",
    "#   print(test_x.shape)\n",
    "test_size = num_data//k_fold\n",
    "test_slice_x = []\n",
    "test_slice_y = []\n",
    "remainder_x = []\n",
    "remainder_y = []\n",
    "total_pred_y = []\n",
    "total_test_y = []\n",
    "\n",
    "# X[:test_size]\n",
    "# test_size\n",
    "# num_data\n",
    "\n",
    "for i in range(k_fold):\n",
    "  if i == 0:\n",
    "    test_slice_x, remainder_x = X[:test_size], X[test_size:]\n",
    "    test_slice_y, remainder_y = Y[:test_size], Y[test_size:]\n",
    "  else:\n",
    "    start = (i-1)*(test_size)\n",
    "    end = min(start + (test_size), num_data)\n",
    "    remainder_x[start:end], test_slice_x = test_slice_x, remainder_x[start:end].copy()\n",
    "    remainder_y[start:end], test_slice_y = test_slice_y, remainder_y[start:end].copy()\n",
    "  # print(test_slice_y)\n",
    "  # # print(y_test)\n",
    "  # print('test_x: ', test_slice_x, 'train_x:', remainder_x)\n",
    "  # print('test_y: ', test_slice_y, 'train_y: ', remainder_y)\n",
    "  model.fit(remainder_x, remainder_y, batch_size=1, epoch=50)\n",
    "  y_pred = model.predict(test_slice_x)\n",
    "  decode_test_y = []\n",
    "  for i in test_slice_y:\n",
    "    decode_test_y.append(np.argmax(i))\n",
    "  decode_pred_y = []\n",
    "  for i in y_pred:\n",
    "    decode_pred_y.append(np.argmax(i))\n",
    "  \n",
    "  # total_pred_y += decode_pred_y\n",
    "  # total_test_y += decode_test_y\n",
    "  print(decode_pred_y)\n",
    "  print(decode_test_y)\n",
    "  conf_mat = confusion_matrix_local(decode_pred_y, decode_test_y)\n",
    "  print(\"Performance Metrics:\")\n",
    "  temp_list = decode_pred_y + decode_test_y\n",
    "  temp_np = np.array(temp_list)\n",
    "  classes = np.unique(temp_np)\n",
    "  print(classes)\n",
    "  print_scores(conf_mat,classes)\n",
    "  accurations.append(accuracy_score(y_pred=decode_pred_y, y_true=decode_test_y))\n",
    "  model.reset()\n",
    "\n",
    "# print(\"predicted label:\")\n",
    "# print(total_pred_y)\n",
    "# print(\"true label:\")\n",
    "# print(total_test_y)\n",
    "# print(\"accuracy:\")\n",
    "# print(accuracy_score(y_pred=total_pred_y, y_true=total_test_y))\n",
    "# print(\"confusion matrix:\")\n",
    "# print(confusion_matrix(total_pred_y, total_test_y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0, 1.0, 1.0, 0.3333333333333333, 0.0, 0.0, 1.0, 0.8, 0.4, 1.0]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6533333333333333"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.average(accurations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pembelajaran full training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "instance:  [[5 4 3 2]]\n",
      "Predicted label: Iris-versicolor\n"
     ]
    }
   ],
   "source": [
    "model.fit(X, Y, batch_size=1, epoch=50)\n",
    "# Dump model\n",
    "dump(model, \"fulltraining_model.json\")\n",
    "\n",
    "# Load data model\n",
    "loaded_data = load(\"fulltraining_model.json\")\n",
    "\n",
    "loaded_model = Sequential()\n",
    "loaded_model.useJSON(loaded_data)\n",
    "\n",
    "instance = np.array([[5,4,3,2]])\n",
    "print(\"instance: \", instance)\n",
    "result = model.predict(instance)[0]\n",
    "labels = [\"Iris-setosa\",\"Iris-versicolor\",\"Iris-virginica\"]\n",
    "label = \"none\"\n",
    "for i in range(len(result)):\n",
    "  if(result[i] == np.max(result)):\n",
    "      label = labels[i]\n",
    "      break\n",
    "print(\"Predicted label:\", label)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "912a385c51eb6c5e7722deaa3d69ac233c1539832e74272ada8aaebb7d379777"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('artificialneuralnetwork-ptGnph6k-py3.8')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
